{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_preprocess2 import split_overflow_table\n",
    "from utils import Config, loadpkl, make_dirs, mp, flatten_1_deg\n",
    "import models\n",
    "from dataset import T2VDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TREC_model():\n",
    "    def __init__(self, data, output_dir, config):\n",
    "        self.data = data\n",
    "        self.config = config\n",
    "        self.file_path = os.path.join(output_dir, config['trec']['file_name'])\n",
    "        self.prep_data()\n",
    "        make_dirs(output_dir)\n",
    "\n",
    "    def prep_data(self):\n",
    "        x_bf = ['row', 'col', 'nul', 'in_link', 'out_link', 'pgcount', 'tImp', 'tPF', 'leftColhits', 'SecColhits', 'bodyhits', 'PMI', 'qInPgTitle', 'qInTableTitle', 'yRank', 'csr_score', 'idf1',\n",
    "                'idf2', 'idf3', 'idf4', 'idf5', 'idf6', 'max', 'sum', 'avg', 'sim', 'emax', 'esum', 'eavg', 'esim', 'cmax', 'csum', 'cavg', 'csim', 'remax', 'resum', 'reavg', 'resim', 'query_l']\n",
    "        x_smf = ['early_fusion', 'late_fusion_max',\n",
    "                 'late_fusion_avg', 'late_fusion_sum']\n",
    "        x_f = x_bf\n",
    "        y_f = ['rel']\n",
    "        if self.config['trec']['semantic_f']:\n",
    "            x_f += x_smf\n",
    "\n",
    "        self.X = self.data[x_f]\n",
    "        self.y = self.data[y_f]\n",
    "\n",
    "    def train(self):\n",
    "        kfold = KFold(5, True, 42)\n",
    "        for i, indices in enumerate(kfold.split(self.X)):\n",
    "            train_idx, test_idx = indices\n",
    "            X_train, X_test, y_train, y_test = self.X.iloc[train_idx], self.X.iloc[\n",
    "                test_idx], self.y.iloc[train_idx], self.y.iloc[test_idx]\n",
    "            df = self.makeModel_getdf(X_train, X_test, y_train, y_test)\n",
    "            df.to_csv(f\"{self.file_path}{i}.txt\",\n",
    "                      sep=' ', index=False, header=False)\n",
    "\n",
    "    def makeModel_getdf(self, X_train, X_test, y_train, y_test):\n",
    "        # self.clf = XGBClassifier(\n",
    "            # tree_method='gpu_hist',\n",
    "            # gpu_id=self.config['gpu']\n",
    "            # )\n",
    "        # self.clf = AdaBoostClassifier(\n",
    "        #     n_estimators=1000,\n",
    "        #     learning_rate=1,\n",
    "        #     random_state=42)\n",
    "        self.clf = RandomForestClassifier(\n",
    "            n_estimators=1000,\n",
    "            max_features=3,\n",
    "            random_state=42)\n",
    "        self.clf.fit(X_train, y_train.values.ravel())\n",
    "        # self.clf.fit(X_train.values, y_train.values)\n",
    "        # X_test = self.score_mp(X_test)\n",
    "        X_test = mp(X_test, self.score_mp, 20)\n",
    "        df = self.generate_trec_df(self.generate_filtered_df(X_test, y_test))\n",
    "        return df\n",
    "\n",
    "    def score_mp(self, X_test):\n",
    "        X_test['model_score'] = X_test.apply(\n",
    "            lambda x: self.getScore(x), axis=1)\n",
    "        return X_test\n",
    "\n",
    "    def getScore(self, row):\n",
    "        arr = self.clf.predict_proba(np.array(row).reshape(1, -1))\n",
    "        return arr[0][1] + 2 * arr[0][2]\n",
    "\n",
    "    def generate_filtered_df(self, X, y):\n",
    "        df = pd.concat([\n",
    "            self.data.iloc[list(X.index)][['query_id', 'query', 'table_id']],\n",
    "            X['model_score']], axis=1)\n",
    "        return df\n",
    "\n",
    "    def generate_trec_df(self, df):\n",
    "        l = []\n",
    "        dic = dict(df.query_id.value_counts())\n",
    "        for i in dic:\n",
    "            for j in range(1, dic[i] + 1):\n",
    "                l.append(j)\n",
    "\n",
    "        df_temp = pd.DataFrame()\n",
    "        df_temp['query_id'] = df['query_id']\n",
    "        df_temp['Q0'] = 'Q0'\n",
    "        df_temp['table_id'] = df['table_id']\n",
    "        df_temp['rank'] = l\n",
    "        df_temp['score'] = df['model_score']\n",
    "        df_temp['smarttable'] = 'smarttable'\n",
    "        return df_temp\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--path\",\n",
    "                        help=\"path for the scores\")\n",
    "    parser.add_argument(\"-m\", \"--model_name\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TREC_data_prep():\n",
    "    def __init__(self, model, config, vocab):\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def convert2table(self, inp, typ):\n",
    "        if typ == 'table':\n",
    "            if len(inp) == 0:\n",
    "                inp = [[['<PAD>']]]\n",
    "            else:\n",
    "                for row in inp:\n",
    "                    for j, cell in enumerate(row):\n",
    "                        if len(row[j]) == 0:\n",
    "                            row[j].append('<PAD>')\n",
    "        if typ == 'query':\n",
    "            inp = [[[j] for j in inp]]\n",
    "        return inp\n",
    "    \n",
    "    def prepare_data2(self, df, typ):\n",
    "        for index, row in df.iterrows():\n",
    "            inp = eval(row[f\"{typ}_tkn\"])\n",
    "            inp =  self.convert2table(inp,typ)\n",
    "            inp = split_overflow_table(inp)\n",
    "            for i in range(len(inp)):\n",
    "                inp[i] = T2VDataset.pad_table(\n",
    "                    self.config['table_prep_params'], inp[i], '<PAD>')\n",
    "            inp = T2VDataset.table_words2index(self.vocab, inp)\n",
    "            inp = np.array(inp)\n",
    "            rows2add = [row] * inp.shape[0]\n",
    "            for i in range(inp.shape[0]):\n",
    "                rows2add[i][f\"{typ}_ft\"] = inp[i]\n",
    "            df = df.drop(index)\n",
    "            df = pd.concat([df, pd.DataFrame(rows2add)])\n",
    "        return df\n",
    "\n",
    "    def late_fusion(self, table, query):\n",
    "        s = []\n",
    "        for i in query:\n",
    "            for j in table:\n",
    "                sim = cosine_similarity(\n",
    "                    np.array(i).reshape(1, -1),\n",
    "                    np.array(j).reshape(1, -1))\n",
    "                s.append(sim)\n",
    "        s = np.array(s).reshape(-1)\n",
    "        return s\n",
    "\n",
    "    def early_fusion(self, table, query):\n",
    "        a = np.average(table, axis=0).reshape(1, -1)\n",
    "        b = np.average(query, axis=0).reshape(1, -1)\n",
    "        sim = cosine_similarity(a, b)\n",
    "        return sim.reshape(-1)[0]\n",
    "\n",
    "    def pipeline(self, baseline_f,device):\n",
    "        baseline_f = self.prepare_data2(baseline_f, 'table')\n",
    "        baseline_f = self.prepare_data2(baseline_f, 'query')\n",
    "        baseline_f['table_ft'] = model(torch.tensor(baseline_f['table_ft'].tolist(),device=device)).cpu().detach().numpy().tolist()\n",
    "        baseline_f['query_ft'] = model(torch.tensor(baseline_f['query_ft'].tolist(),device=device)).cpu().detach().numpy().tolist()\n",
    "\n",
    "        baseline_f['early_fusion'] = baseline_f.apply(\n",
    "            lambda x: self.early_fusion(x['table_ft'], x['query_ft']), axis=1)\n",
    "        baseline_f['late_fusion'] = baseline_f.apply(\n",
    "            lambda x: self.late_fusion(x['table_ft'], x['query_ft']), axis=1)\n",
    "        \n",
    "        baseline_f['late_fusion_max'] = baseline_f.late_fusion.apply(\n",
    "            np.max)\n",
    "        baseline_f['late_fusion_avg'] = baseline_f.late_fusion.apply(\n",
    "            np.average)\n",
    "        baseline_f['late_fusion_sum'] = baseline_f.late_fusion.apply(\n",
    "            np.sum)\n",
    "        \n",
    "        baseline_f.drop(columns=['table_ft', 'query_ft'], inplace=True)\n",
    "\n",
    "        return baseline_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = get_args()\n",
    "args = dotdict({\"path\":'output/5_25_11_25_39', 'model_name':'model_3.pt'})\n",
    "start_time = time.time()\n",
    "\n",
    "config = Config()\n",
    "config.load(os.path.join(args.path, 'config.toml'))\n",
    "\n",
    "vocab = loadpkl(config['input_files']['vocab_path'])\n",
    "device = torch.device(f\"cuda:{config['gpu']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Table2Vec(\n",
      "  (embeddings): Embedding(2533498, 100)\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(100, 128, kernel_size=(3, 2), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(128, 64, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=640, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Table2Vec(\n",
       "  (embeddings): Embedding(2533498, 100)\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(100, 128, kernel_size=(3, 2), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(128, 64, kernel_size=(2, 1), stride=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "  )\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Linear(in_features=640, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.create_model(\n",
    "    config['model_props']['type'],\n",
    "    params=(\n",
    "        len(vocab),\n",
    "        config['model_params']['embedding_dim'],\n",
    "        device\n",
    "    )\n",
    ")\n",
    "model.to(device)\n",
    "state_dict = torch.load(os.path.join(args.path, args.model_name))\n",
    "model.linear_layers = torch.nn.Sequential(\n",
    "    *(list(model.linear_layers.children())[:2]))\n",
    "state_dict_ = OrderedDict(\n",
    "    {i: state_dict[i] for i in list(model.state_dict())})\n",
    "model.load_state_dict(state_dict_)\n",
    "print(torch.equal(list(model.parameters())[\n",
    "      0], state_dict_['embeddings.weight']))\n",
    "print(model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the df and features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibhav_student/.conda/envs/t2v_pt/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = None\n",
    "baseline_f = pd.read_csv(config['input_files']['baseline_f'])\n",
    "trec = TREC_data_prep(model, config, vocab)\n",
    "baseline_f = trec.pipeline(baseline_f,device)\n",
    "# baseline_f = mp(\n",
    "#     df=baseline_f, func=trec.pipeline, num_partitions=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6560, 46)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_f.to_csv('./data/w_all_data/baseline_f_tq-tkn_lst_ft.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trec_model = TREC_model(data=baseline_f, output_dir=trec_path, config=config)\n",
    "trec_model.train()\n",
    "ndcg_score, ndcg_score_dict = ndcg_pipeline(\n",
    "    trec_model.file_path,\n",
    "    '../trec_eval/trec_eval',\n",
    "    '../global_data/qrels.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6560, 15, 5, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(baseline_f['table_ft'].tolist()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.tensor(baseline_f['table_ft'].tolist(),device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6560, 256])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6560"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out.cpu().detach().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python37564bitb64b7bd534634d14b355f6a5722a54fe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
